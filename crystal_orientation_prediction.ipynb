{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bae0d09-50e6-479e-95b4-fa000b6ab04a",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa695a-e35e-4bab-b86a-606e80cfe2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy import optimize\n",
    "import time, datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e55670-8f68-4f49-a480-04509e6cdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define \n",
    "phi = np.radians(np.linspace(0,45,100+1))\n",
    "phi, phi.shape,len(phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e995b-e007-44b5-a1ba-c3316c3e766b",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc2f20-6ac9-4820-8b6b-acabc933c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.style.use('normal.mplstyle')\n",
    "\n",
    "def draw_standard_triangle(polar=False, dpi=80, figsize=None):\n",
    "    \"\"\"Draw Standard stereographic triangle.\"\"\"\n",
    "    # Plot data\n",
    "    phi = np.radians(np.linspace(0,45,100+1))\n",
    "    r = -np.cos(phi) + np.sqrt(np.power(np.cos(phi),2)+1) #101 to 111\n",
    "    phi = np.hstack((0,phi,0)); r = np.hstack((0,r,0))\n",
    "    x = r*np.cos(phi); y = r*np.sin(phi)\n",
    "    x0, y0 = (0, 0)\n",
    "    x1, y1 = (x[1], y[1])\n",
    "    x2, y2 = (x[-2], y[-2])\n",
    "    \n",
    "    # Get Figure\n",
    "    plt.style.use('default')\n",
    "    if os.path.exists('IPF.mplstyle'):\n",
    "        plt.style.use('IPF.mplstyle')\n",
    "    projection = 'polar' if polar else None\n",
    "    fig, axes = plt.subplots(subplot_kw=dict(projection=projection),\n",
    "                             dpi=dpi, figsize=figsize, squeeze=False)\n",
    "    ax = axes[0,0]\n",
    "    ax.set_aspect('equal')\n",
    "    if polar:\n",
    "        plt.axis('off')\n",
    "        ax.set_thetalim(0, math.radians(45))\n",
    "    \n",
    "    # Draw triangle\n",
    "    u = phi if polar else x\n",
    "    v = r if polar else y\n",
    "    ax.plot(u, v, 'k-', zorder=0)\n",
    "    \n",
    "    def pos(x,y,polar):\n",
    "        if polar:\n",
    "            return math.atan2(y,x), np.linalg.norm([x,y])\n",
    "        else:\n",
    "            return x,y\n",
    "\n",
    "    v_list = ['001','101','111']\n",
    "    x_list = [x0-0.005, x1+0.005, x2]\n",
    "    y_list = [y0, y1, y2+0.005]\n",
    "    c_list = ['red', 'green', 'blue']\n",
    "    ha_list = ['right','left','left']\n",
    "    va_list = ['top','top','bottom']\n",
    "    for v,x,y,c,ha,va in zip(v_list,x_list,y_list,c_list,ha_list,va_list):\n",
    "        ax.text(*pos(x,y,polar),v, size=11, c=c, ha=ha, va=va)    \n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "class ColormapInSST:\n",
    "    \"\"\"\n",
    "    Color map in standard stereographic triangle (SST).\n",
    "    \"\"\"\n",
    "    \"\"\" Vertices \"\"\"\n",
    "    x0 = 0; x1 = np.sqrt(2)-1; x2 = (np.sqrt(3)-1)/2\n",
    "    p0 = np.array([0,0]); p1 = np.array([x1, 0]); p2 = np.array([x2, x2])\n",
    "    pG = (p0+p1+p2)/3\n",
    "    \n",
    "    \"\"\" Segments \"\"\"\n",
    "    m0 = p0 - pG; m1 = p1 - pG; m2 = p2 - pG\n",
    "    s0 = p1 - p0; s2 = p0 - p2\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.fig, self.ax = draw_standard_triangle()\n",
    "        distance = lambda p, s, ps: np.abs(np.cross(s,p-ps))/np.linalg.norm(s)\n",
    "        self.L_P0_M1 = distance(self.p0, self.m1, self.pG)\n",
    "        self.L_P0_M2 = distance(self.p0, self.m2, self.pG)\n",
    "        self.L_P1_M2 = distance(self.p1, self.m2, self.pG)\n",
    "        self.L_P1_M0 = distance(self.p1, self.m0, self.pG)\n",
    "        self.L_P2_M0 = distance(self.p2, self.m0, self.pG)\n",
    "        self.L_P2_M1 = distance(self.p2, self.m1, self.pG)\n",
    "\n",
    "        self.L_PG_S0 = distance(self.pG, self.s0, self.p0)\n",
    "        self.L_PG_S2 = distance(self.pG, self.s2, self.p2)\n",
    "    \n",
    "    def get_RGB(self, p:list):\n",
    "        p = np.array(p)\n",
    "        is_inside = ((p[0]+1)**2+p[1]**2<=np.sqrt(2)**2\n",
    "                      and p[1]<=p[0] and p[1]>=0)\n",
    "        \n",
    "        \"\"\" Open self \"\"\"\n",
    "        p0,p1,p2,pG = self.p0,self.p1,self.p2,self.pG\n",
    "        points = [p0,p1,p2,pG]\n",
    "        \n",
    "        \"\"\" Functions \"\"\"\n",
    "        is_above = lambda p, v: 1/np.divide(*(pG-v))*(p[0]-pG[0])+pG[1]<=p[1]\n",
    "        distance = lambda p, s, ps: np.abs(np.cross(s,p-ps))/np.linalg.norm(s)\n",
    "        slope = 1/np.divide(*(pG-p))\n",
    "        def f(x):\n",
    "            y  = (x+1)**2-2 + (slope*(x-pG[0])+pG[1])**2\n",
    "            dy = 2*(x+1) + 2*y*slope\n",
    "            ddy = 2 + 2*slope**2\n",
    "            return y, dy, ddy\n",
    "        \n",
    "        \"\"\" In case : p is at P0, P1, P2, or PG \"\"\"        \n",
    "        if not is_inside:\n",
    "            self.RGB = [1,1,1]\n",
    "        elif np.any(p.tolist()==points):\n",
    "            points = np.vstack(points).tolist()\n",
    "            RGB_on_v = [[1,0,0],[0,1,0],[0,0,1],[1,1,1]]\n",
    "            self.RGB = RGB_on_v[points.index(p.tolist())]\n",
    "        else:\n",
    "            \"\"\" Otherwise \"\"\"\n",
    "            s0, s2 = self.s0, self.s2\n",
    "            m0, m1, m2 = self.m0, self.m1, self.m2\n",
    "\n",
    "            if is_above(p,p2) and not is_above(p,p1): # in mainR:\n",
    "                r = 1\n",
    "                if not is_above(p, p0): # in sub0\n",
    "                    g = 1 - distance(p, m2, pG)/self.L_P0_M2\n",
    "                    b = distance(p, s0, p0)/self.L_PG_S0\n",
    "                else: # in sub2:\n",
    "                    b = 1 - distance(p, m1, pG)/self.L_P0_M1\n",
    "                    g = distance(p, s2, p2)/self.L_PG_S2\n",
    "            elif not is_above(p,p0) and not is_above(p,p2):  # in mainG:\n",
    "                g = 1\n",
    "                if not is_above(p, p1): # in sub0:\n",
    "                    r = 1 - distance(p, m2, pG)/self.L_P1_M2\n",
    "                    b = distance(p, s0, p0)/self.L_PG_S0\n",
    "                else: # in sub1:\n",
    "                    b = 1 - distance(p, m0, pG)/self.L_P1_M0\n",
    "                    sol = optimize.root_scalar(f, x0=0.35, fprime=True,\n",
    "                                               fprime2=True, method='halley')\n",
    "                    x_sol = np.max(sol.root)\n",
    "                    px = np.array([x_sol, slope*(x_sol-pG[0])+pG[1]])\n",
    "                    r = np.linalg.norm(p-px)/np.linalg.norm(pG-px)\n",
    "            else: # in mainB:\n",
    "                b = 1\n",
    "                if not is_above(p, p2): # in sub1:\n",
    "                    g = 1 - distance(p, m0, pG)/self.L_P2_M0\n",
    "                    sol = optimize.root_scalar(f, x0=0.35, fprime=True,\n",
    "                                               fprime2=True, method='halley')\n",
    "                    x_sol = np.max(sol.root)\n",
    "                    px = np.array([x_sol, slope*(x_sol-pG[0])+pG[1]])\n",
    "                    r = np.linalg.norm(p-px)/np.linalg.norm(pG-px)                    \n",
    "                else: # in sub2:\n",
    "                    r = 1 - distance(p, m1, pG)/self.L_P2_M1\n",
    "                    g = distance(p, s2, p2)/self.L_PG_S2\n",
    "            self.RGB = [r,g,b]\n",
    "        #self.ax.scatter(*p, color=self.RGB, edgecolors='k')\n",
    "        return np.array(self.RGB)\n",
    "\n",
    "\n",
    "\n",
    "def get_time_stamp(time_start):\n",
    "    \"\"\"\n",
    "    Return time stamp to check progress.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    time_start : float\n",
    "        Start time obtained by time.time()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    time_s : str\n",
    "        stamp to show elapsed time.\n",
    "    date_s : str\n",
    "        stamp to show date.\n",
    "    \"\"\"\n",
    "    time_elapsed = time.time() - time_start\n",
    "    hour = int(time_elapsed//3600)\n",
    "    hour_s = f'{hour} hour ' if hour>0 else ''\n",
    "    min_s = f'{int(time_elapsed%3600//60)} min '\n",
    "    sec_s = f'{str(int(time_elapsed%60)).zfill(2)} sec'\n",
    "    time_s = f'{hour_s}{min_s}{sec_s}'\n",
    "    date_s = datetime.datetime.now().strftime('%m-%d %H:%M:%S')\n",
    "    return time_s, date_s\n",
    "\n",
    "\n",
    "direction_dict = dict(ND=np.array([0,0,0,1]),\n",
    "                      RD=np.array([0,1,0,0]),\n",
    "                      TD=np.array([0,0,1,0]))\n",
    "\n",
    "\n",
    "# Quaternion operation\n",
    "def q_mul(q1, q2):\n",
    "    q31 = q1[0]*q2[0] - q1[1]*q2[1] - q1[2]*q2[2] - q1[3]*q2[3]\n",
    "    q32 = q1[0]*q2[1] + q1[1]*q2[0] + q1[2]*q2[3] - q1[3]*q2[2]\n",
    "    q33 = q1[0]*q2[2] - q1[1]*q2[3] + q1[2]*q2[0] + q1[3]*q2[1]\n",
    "    q34 = q1[0]*q2[3] + q1[1]*q2[2] - q1[2]*q2[1] + q1[3]*q2[0]\n",
    "    return np.array([q31,q32,q33,q34])\n",
    "\n",
    "\n",
    "def norm(q):\n",
    "    return q/np.linalg.norm(q)\n",
    "\n",
    "\n",
    "def inverse(q):\n",
    "    return np.array([q[0],-q[1],-q[2],-q[3]])\n",
    "\n",
    "\n",
    "def sym_q_list(q_f, type_rot='ipf'):\n",
    "    rot_equiv = np.array([\n",
    "        [1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 1, 0],[0, 0, 0, 1],\n",
    "        [0.5, 0.5, 0.5, 0.5],[-0.5, 0.5, 0.5, 0.5],\n",
    "        [0.5, -0.5, 0.5, 0.5],[-0.5, -0.5, 0.5, 0.5],\n",
    "        [0.5, 0.5, -0.5, 0.5],[-0.5, 0.5, -0.5, 0.5],\n",
    "        [0.5, 0.5, 0.5, -0.5],[-0.5, 0.5, 0.5, -0.5],\n",
    "        [1/math.sqrt(2), 1/math.sqrt(2), 0, 0],\n",
    "        [-1/math.sqrt(2), 1/math.sqrt(2), 0, 0],\n",
    "        [1/math.sqrt(2), 0, 1/math.sqrt(2), 0],\n",
    "        [-1/math.sqrt(2), 0, 1/math.sqrt(2), 0],\n",
    "        [1/math.sqrt(2), 0, 0, 1/math.sqrt(2)],\n",
    "        [-1/math.sqrt(2), 0, 0, 1/math.sqrt(2)],\n",
    "        [0, 1/math.sqrt(2), 1/math.sqrt(2), 0],\n",
    "        [0, 1/math.sqrt(2), -1/math.sqrt(2), 0],\n",
    "        [0, 0, 1/math.sqrt(2), 1/math.sqrt(2)],\n",
    "        [0, 0, 1/math.sqrt(2), -1/math.sqrt(2)],\n",
    "        [0, 1/math.sqrt(2), 0, 1/math.sqrt(2)],\n",
    "        [0, -1/math.sqrt(2), 0, 1/math.sqrt(2)]\n",
    "    ]) \n",
    "    if type_rot=='ipf': # Frame-rot.\n",
    "        q_list_eq = np.array([q_mul(q_f, r) for r in rot_equiv])\n",
    "    elif type_rot=='pf': # Vector-rot.\n",
    "        q_list_eq = np.array([q_mul(r, q_f) for r in rot_equiv])\n",
    "    q_list_eq = np.array([q if q[0]>=0 else -q for q in q_list_eq])\n",
    "    return q_list_eq\n",
    "\n",
    "\n",
    "def unique_q(q_f, type_rot='ipf'):\n",
    "    q_list_eq = sym_q_list(q_f, type_rot)\n",
    "    return q_list_eq[q_list_eq[:,0].argmax(axis=0)]\n",
    "\n",
    "\n",
    "def rot_vector(q, v, type_rot='B'):\n",
    "    v = np.array([0, *v])\n",
    "    if type_rot=='A':\n",
    "        return q_mul(q, q_mul(v, inverse(q)))[1:]\n",
    "    elif type_rot=='B':\n",
    "        return q_mul(inverse(q), q_mul(v, q))[1:]\n",
    "\n",
    "\n",
    "\n",
    "def ori_sub_calc(q1,q2):\n",
    "    qd = q_mul(q1, inverse(q2))\n",
    "    qd_list = sym_q_list(qd)\n",
    "    residual = 2*math.degrees(math.acos(qd_list[:,0].max(axis=0)))\n",
    "    print('min_ori_sub')\n",
    "    print(residual)\n",
    "    return residual\n",
    "\n",
    "\n",
    "def ipf_vector(q_in, direction='ND'):\n",
    "    direction_dict = dict(ND=np.array([0,0,0,1]),\n",
    "                          RD=np.array([0,1,0,0]),\n",
    "                          TD=np.array([0,0,1,0]))\n",
    "    c = direction_dict[direction]\n",
    "    v = q_mul(q_mul(inverse(q_in),c), q_in)[1:]\n",
    "    if v[-1]<0:\n",
    "        v = -v\n",
    "    return v\n",
    "\n",
    "\n",
    "def stereographic(v, in_sst=False):\n",
    "    \"\"\"Return stereographic position.\"\"\"\n",
    "    if in_sst:\n",
    "        y, x, z = np.sort(np.abs(v))\n",
    "    else:\n",
    "        x, y, z = v\n",
    "    r = np.linalg.norm(v)\n",
    "    xs, ys = np.array([x, y])/(r+abs(z))\n",
    "    return xs, ys\n",
    "\n",
    "def ipf_plot(q_in, direction='ND'):\n",
    "    v = ipf_vector(q_in, direction)\n",
    "    return stereographic(v, in_sst=False)\n",
    "\n",
    "def ipf_color(v):\n",
    "    xs, ys = stereographic(v, in_sst=True)\n",
    "    cm = ColormapInSST()\n",
    "    return cm.get_RGB([xs, ys])\n",
    "\n",
    "\n",
    "def stereo_projection(hkl):\n",
    "    y = hkl[2]/(hkl[1]+1)\n",
    "    z = hkl[3]/(hkl[1]+1)\n",
    "    return y,z\n",
    "\n",
    "\n",
    "def draw_projection_plane():\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    \n",
    "    # Draw circle.\n",
    "    cir_x = np.sin(np.radians(np.arange(-180,181,1)))\n",
    "    cir_y = np.cos(np.radians(np.arange(-180,181,1)))\n",
    "    ax.plot(cir_x,cir_y,color=[0,0,0])\n",
    "\n",
    "    # Plot symmetric points.\n",
    "    base_vec = np.array([\n",
    "        [0,1, 0, 0],[0,0, 1, 0],[0,0, 0, 1],\n",
    "        [0,0,-1, 0],[0,0, 0, -1],\n",
    "        [0,1, 1, 0], [0,1, -1, 0],\n",
    "        [0,1, 0,1], [0,1, 0,-1],\n",
    "        [0,0,1,1],[0,0,-1,1],[0,0,1,-1],[0,0,-1,-1],\n",
    "        [0,1,1,1],[0,1,-1,1],[0,1,1,-1],[0,1,-1,-1],\n",
    "        [0,1,1,2],[0,1,-1,2],[0,1,1,-2],[0,1,-1,-2],\n",
    "        [0,1,2,1],[0,1,2,-1],[0,1,-2,1],[0,1,-2,-1],\n",
    "        [0,2,1,1],[0,2,-1,1],[0,2,1,-1],[0,2,-1,-1]])\n",
    "    ss_list = np.sum(base_vec**2,axis=1)\n",
    "    norm_list = np.sqrt(ss_list)\n",
    "    base_vec_norm = np.array([base_vec/norm\n",
    "                              for base_vec, norm\n",
    "                              in zip(base_vec, norm_list)])\n",
    "    base_yz = np.array([stereo_projection(v) for v in base_vec_norm])\n",
    "    marker_dict = {1:\"s\", 2:\"d\", 3:\"^\", 6:\"8\"}\n",
    "    marker_list = [marker_dict[ss] for ss in ss_list]\n",
    "\n",
    "    for (y, z), marker in zip(base_yz, marker_list):\n",
    "        ax.scatter(y, z, color=[0,0,0], s=200, marker=marker)\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a22fc2-7b02-4876-9dff-a6889ebf4d83",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2577c3-2b42-4ae2-81e9-e0c336750b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "folder = 'npy_data'\n",
    "\n",
    "#for learning\n",
    "wafers = [['K2', 'No200'],['K2', 'No450'],['K2', 'No700']]\n",
    "\n",
    "#for predicting: K3\n",
    "wafers_predict = [['K3', 'No250'],['K3', 'No450'],['K3', 'No545'],['K3', 'No650']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1b28c-c44a-44e2-bfee-d5d60e95b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load luminance data for each grain\n",
    "lum60 = np.vstack([np.load(f'{folder}/lum_mean_{ingot}_{wafer_num}_60.npy') for ingot, wafer_num in wafers])\n",
    "lum45 = np.vstack([np.load(f'{folder}/lum_mean_{ingot}_{wafer_num}_45.npy') for ingot, wafer_num in wafers])\n",
    "lum30 = np.vstack([np.load(f'{folder}/lum_mean_{ingot}_{wafer_num}_30.npy') for ingot, wafer_num in wafers])\n",
    "lum = np.array([lum60,lum45,lum30])\n",
    "lum = lum.transpose(1,2,0)\n",
    "\n",
    "#load teacher data for each grain\n",
    "r = np.vstack([np.load(f'npy data/q_wxyz_asscipy_{ingot}_{wafer_num}.npy') for ingot, wafer_num in wafers ])\n",
    "r = np.array([r0/L for r0,L in zip(r, np.linalg.norm(r, axis=1))])\n",
    "r = r*np.sign(r[:,-1]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b4560-07ab-4c11-8e6a-7f1263e4a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set id\n",
    "test_id = 1\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def l2normalize(x):\n",
    "    x = K.l2_normalize(x, axis=1)\n",
    "    return x\n",
    "\n",
    "def get_model(type_model='lstm', model_id='test',test_id=None, ss=72):\n",
    "    \n",
    "    n = 3  #n is the number of elevations used; 1 for single angle training, 2 or 3 for double or triple angle training.    \n",
    "    lum_shape = (ss, n)\n",
    "\n",
    "    if model_id==0:        \n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(units=128, input_shape=lum_shape),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(4),\n",
    "            tf.keras.layers.Activation(l2normalize)])\n",
    "        return model\n",
    "    \n",
    "    elif model_id==1:\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(units=128, input_shape=lum_shape),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(4),\n",
    "            tf.keras.layers.Activation(l2normalize)])\n",
    "        return model\n",
    "    \n",
    "    elif model_id==2:\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(units=128, input_shape=lum_shape),\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(4),\n",
    "            tf.keras.layers.Activation(l2normalize)])\n",
    "        return model        \n",
    "\n",
    "\n",
    "# Setting\n",
    "ss = 72\n",
    "model_id = 0 \n",
    "type_model = ['lstm', 'conv1d'][0]\n",
    "\n",
    "model=get_model(type_model=type_model,\n",
    "                model_id=model_id, test_id = test_id,\n",
    "                ss=ss)\n",
    "\n",
    "model.summary()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d0335-6878-4fff-9db4-8f88cbafc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def rotate_data(lum, r, N_lum=72, step=36):\n",
    "    \"\"\"\n",
    "    Data augumentation by rotating data.\n",
    "    \"\"\"\n",
    "    q_cubic = [[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1],\n",
    "               [1,1,1,1], [-1,1,1,1], [1,-1,1,1], [-1,-1,1,1],\n",
    "               [1,1,-1,1], [-1,1,-1,1], [1,1,1,-1], [-1,1,1,-1],\n",
    "               [1,1,0,0], [-1,1,0,0], [1,0,1,0], [-1,0,1,0],\n",
    "               [1,0,0,1], [-1,0,0,1], [0,1,1,0], [0,1,-1,0],\n",
    "               [0,0,1,1], [0,0,1,-1], [0,1,0,1], [0,-1,0,1]]\n",
    "    B_cubic = R.from_quat(np.roll(q_cubic,-1,axis=1)).inv()\n",
    "    \n",
    "    shift = np.arange(step, N_lum, step)\n",
    "    lum_shifted = np.vstack([np.roll(lum, i, axis=1) for i in shift])\n",
    "    \n",
    "    theta_shift = 2*math.pi*shift/N_lum\n",
    "    r_shift = np.array([[0, 0, z, w] for w, z in zip(np.cos(-theta_shift/2), np.sin(-theta_shift/2))])\n",
    "    B_shift = R.from_quat(r_shift)\n",
    "\n",
    "    B = R.from_quat(np.roll(r, -1, axis=1)).inv()\n",
    "    \n",
    "    r_shifted = np.vstack([(Bi*B).reduce(right=B_cubic).inv().as_quat() for Bi in B_shift])\n",
    "    r_shifted = np.roll(r_shifted, 1, axis=1)\n",
    "    r_shifted = r_shifted * np.sign(r_shifted[:,0]).reshape(-1,1)\n",
    "    \n",
    "    return lum_shifted, r_shifted\n",
    "\n",
    "def pickle_object(obj, path):\n",
    "    with open(path,\"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def geodesic_distance(y_true, y_pred):\n",
    "    \"\"\"Return mean geodesic distance in radian.\"\"\"\n",
    "    y_pred = K.l2_normalize(y_pred, axis=1)\n",
    "    yy = K.sum(y_true*y_pred, axis=1)\n",
    "    z = 1-1e-6\n",
    "    mgd = K.mean(2*tf.acos(K.abs(K.clip(yy,-z,z))))\n",
    "    return mgd\n",
    "\n",
    "def geodesic_loss(y_true, y_pred):\n",
    "    y_pred = K.l2_normalize(y_pred, axis=1)\n",
    "    yy = K.sum(y_true*y_pred, axis=1)\n",
    "    z = 1-1e-6\n",
    "    yy = K.clip(yy,-z,z)\n",
    "    \n",
    "    if type_loss=='distance':\n",
    "        loss = 2*tf.acos(K.abs(yy))\n",
    "    elif type_loss=='1st':\n",
    "        loss = 1 - K.abs(yy)\n",
    "    elif type_loss=='2nd':\n",
    "        loss = 1 - yy**2\n",
    "    return K.mean(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74feb2a-dca8-4a5e-bf07-bf7db0c5f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Setting\n",
    "test_id = 1\n",
    "seed_rand = [1234, 1234]\n",
    "data_augmentation = False\n",
    "step_aug = 24\n",
    "type_loss = ['distance', '1st', '2nd'][0]\n",
    "ss = ss \n",
    "type_model = type_model\n",
    "\n",
    "# Passive setting\n",
    "result_folder = f'results/{test_id}'\n",
    "tf.random.set_seed(seed_rand[0])\n",
    "os.makedirs(result_folder)\n",
    "\n",
    "model = get_model(type_model=type_model,\n",
    "                  model_id=model_id, test_id = test_id,\n",
    "                  ss=ss)\n",
    "\n",
    "(lum_train, lum_valid, r_train, r_valid) = train_test_split(lum, r, train_size=0.8,\n",
    "                                                          random_state=seed_rand[0])\n",
    "\n",
    "\n",
    "if os.path.exists(f'{result_folder}/weight_all.hdf5'):\n",
    "    model.load_weights(f'{result_folder}/weight_all.hdf5')\n",
    "else:\n",
    "    print(f'test id : {test_id} has no weights')\n",
    "\n",
    "\n",
    "step = 9\n",
    "N_lum = lum.shape[1]\n",
    "print(N_lum)\n",
    "lum_shifted, r_shifted = rotate_data(lum_train, r_train, N_lum=N_lum, step=step)\n",
    "lum_shifted.shape[0]/(72/step-1), r_shifted.shape[0]/(72/step-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37493563-eaa8-43f2-a820-50ffb488ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report Starting Status\n",
    "report = open(f'results/{test_id}_all.txt', mode='w')\n",
    "for item, value in zip(['data', 'model', 'loss', 'seed'],\n",
    "                       [folder, type_model, type_loss, seed_rand]):\n",
    "    report.write(f'{item} : {value}'); report.write('\\n')\n",
    "\n",
    "time_start = time.time()    \n",
    "time_s, date_s = get_time_stamp(time_start)\n",
    "report_time = f'Start | {time_s} | {date_s}'\n",
    "print(report_time)\n",
    "report.write(report_time); report.write('\\n') \n",
    "\n",
    "report_shape = f'Data shape : lum : {lum.shape}, r : {r.shape}'\n",
    "report_size = f'Data size | Train : {len(lum_train)}, Valid : {len(lum_valid)}'\n",
    "print(report_shape)\n",
    "print(report_size)\n",
    "report.write(report_shape); report.write('\\n')\n",
    "report.write(report_size); report.write('\\n')\n",
    "\n",
    "\n",
    "if data_augmentation:\n",
    "    N_lum = lum_train.shape[1]\n",
    "    lum_shifted, r_shifted = rotate_data(lum_train, r_train, N_lum=N_lum, step=step_aug)\n",
    "\n",
    "    if True:\n",
    "        lum_train = np.vstack([lum_train, lum_shifted])\n",
    "        r_train = np.vstack([r_train, r_shifted])\n",
    "    else: # for test\n",
    "        lum_train = lum_shifted\n",
    "        r_train = r_shifted\n",
    "    report_augmentation = f'Augmentation step : {step_aug}, Augmented size | Train : {len(lum_train)}, Valid : {len(lum_valid)}'\n",
    "    print(report_augmentation)\n",
    "    report.write(report_augmentation); report.write('\\n')\n",
    "\n",
    "    \n",
    "#model summary\n",
    "model.summary()\n",
    "print(lum_train.shape, lum_valid.shape)\n",
    "\n",
    "\n",
    "# Prefit\n",
    "epochs = 20\n",
    "batch_size = 959\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model_pre = get_model(type_model=type_model,\n",
    "                      model_id=model_id, test_id = test_id,\n",
    "                      ss=ss)\n",
    "model_pre.compile(loss=\"mae\", optimizer='adam',\n",
    "                  metrics=[geodesic_distance])\n",
    "history_pre = model_pre.fit(x=lum_train, y=r_train,\n",
    "                            validation_data=(lum_valid, r_valid),\n",
    "                            batch_size=batch_size, epochs=epochs,\n",
    "                            verbose=0) # 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "model_pre.save_weights(f'{result_folder}/weight_pre_all.hdf5')\n",
    "pickle_object(history_pre.history, f'{result_folder}/history_pre_all.pickle')\n",
    "pickle_object(history_pre.params, f'{result_folder}/params_pre_all.pickle')\n",
    "\n",
    "# Report 1\n",
    "for item, value in zip(['epochs', 'batch_size'], [epochs, batch_size]):\n",
    "    report.write(f'{item} : {value}'); report.write('\\n')\n",
    "time_s, date_s = get_time_stamp(time_start)\n",
    "report_time = f'Initialized | {time_s} | {date_s}'\n",
    "print(report_time)\n",
    "report.write(report_time); report.write('\\n')\n",
    "\n",
    "\n",
    "# Fit\n",
    "epochs = 8000\n",
    "batch_size = 959\n",
    "\n",
    "for item, value in zip(['epochs', 'batch_size'], [epochs, batch_size]):\n",
    "    report.write(f'{item} : {value}'); report.write('\\n')\n",
    "\n",
    "clipnorm = None \n",
    "optimizer = tf.keras.optimizers.Adam() # 0.0001\n",
    "\n",
    "model = get_model(type_model=type_model,\n",
    "                  model_id=model_id, test_id =test_id,\n",
    "                  ss=ss)\n",
    "model.compile(loss=geodesic_loss, optimizer=optimizer,\n",
    "              metrics=[geodesic_distance])\n",
    "model.load_weights(f'{result_folder}/weight_pre_all.hdf5')\n",
    "\n",
    "\n",
    "# To restore best weights\n",
    "checkpoint_filepath = '/temp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='geodesic_distance',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit(x=lum_train, y=r_train,\n",
    "                    validation_data=(lum_valid, r_valid),\n",
    "                    batch_size=batch_size, epochs=epochs,\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "model.save_weights(f'{result_folder}/weight_all.hdf5')\n",
    "pickle_object(history.history, f'{result_folder}/history_all.pickle')\n",
    "pickle_object(history.params, f'{result_folder}/params_all.pickle')\n",
    "\n",
    "# Report 2-1 : Learning curve\n",
    "fig, ax = plt.subplots(figsize=(5,2.5))\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Mean geodesic error (°)')\n",
    "yt = np.array(history.history['geodesic_distance'])*180/math.pi\n",
    "yv = np.array(history.history['val_geodesic_distance'])*180/math.pi        \n",
    "ax.plot(yt, 'b-', ms=1, lw=0.5)\n",
    "ax.plot(yv, 'r-', ms=1, lw=0.5)\n",
    "ax.set_ylim(0,None)\n",
    "fig.savefig(f'{result_folder}/learning_curve_all.png', dpi=100)\n",
    "\n",
    "time_s, date_s = get_time_stamp(time_start)\n",
    "\n",
    "report_time = f'Done | {time_s} | {date_s}'\n",
    "report_data = f'- Train: {yt[-1]:.2f}°, Validation: {yv[-1]:.2f}° -'\n",
    "print(report_time)   \n",
    "print(report_data)\n",
    "report.write(report_time); report.write('\\n')\n",
    "report.write(report_data); report.write('\\n')\n",
    "\n",
    "\n",
    "# Predict\n",
    "pred_r = model.predict(lum_valid)\n",
    "pred_norm = np.linalg.norm(pred_r, axis=1)\n",
    "pred_r0 = np.array([r/norm for r, norm in zip(pred_r, pred_norm)])\n",
    "\n",
    "gde_list = np.degrees(2*np.arccos(np.abs(np.sum(pred_r0*r_valid, axis=1))))\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "ax.set_xlabel('Estimation error (°)')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.hist(gde_list, 100)\n",
    "fig.savefig(f'{result_folder}/histogram_all.png', dpi=100)\n",
    "\n",
    "# Report 2-2\n",
    "report_data_mean = f'Mean GDE : {np.mean(gde_list):.2f}°'\n",
    "report_data_median = f'Median of GDE : {np.median(gde_list):.2f}°'\n",
    "print(report_data_mean)\n",
    "print(report_data_median)\n",
    "report.write(report_data); report.write('\\n')\n",
    "\n",
    "# Report 3\n",
    "report.write('\\n\\n# Model')\n",
    "model.summary(print_fn=lambda x: report.write(x + \"\\r\\n\"))\n",
    "report.write('\\n\\n# Parameters')\n",
    "for p in history.params.items():\n",
    "    line = [p[0], str(p[1])]\n",
    "    report.writelines(['\\n', ' : '.join(line)])\n",
    "report.close()\n",
    "\n",
    "print(f'Finished test_id : {test_id}')\n",
    "print(history.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf4a04-4d3e-4879-992c-b6783262e6b6",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d68e86-e3ff-400a-9720-529b2b70e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def random_misorientations(deg):\n",
    "    \"\"\"\n",
    "    Return theoretical random misorientation distrbution density.\n",
    "    ---------\n",
    "    Reference\n",
    "    ---------\n",
    "    D. C. Handscomb, Can. J. Math. 10, 85 (1958). \n",
    "    https://doi.org/10.4153/CJM-1958-010-0\n",
    "    \"\"\"\n",
    "    d = np.radians(deg)\n",
    "    if deg < 45:\n",
    "        eq = 2/15*(1-np.cos(d))\n",
    "    elif deg < 60:\n",
    "        eq = 2/15*(3*(np.sqrt(2)-1)*np.sin(d) - 2*(1-np.cos(d)))\n",
    "    elif deg < 2*np.degrees(np.arctan(2-np.sqrt(2))): # = 60.72∘\n",
    "        eq = 2/15*((3*(np.sqrt(2)-1)+4/np.sqrt(3))*np.sin(d)-6*(1-np.cos(d)))\n",
    "    elif deg < np.degrees(np.arccos(1/4*(2*np.sqrt(2)-1))): # = 62.80∘\n",
    "        cot = 1/np.tan(d/2)\n",
    "        t1 = cot**2/(3+2*np.sqrt(2)-cot**2)\n",
    "        t2 = (cot**2-2*np.sqrt(2))/(3-cot**2)\n",
    "        t3 = (np.sqrt(2)-1)*cot/np.sqrt(1-(np.sqrt(2)-1)**2*cot**2)\n",
    "        t4 = (np.sqrt(2)-1)**2*cot/np.sqrt(3-cot**2)\n",
    "        eq = 2/15*((3*(np.sqrt(2)-1)+4/np.sqrt(3))*np.sin(d) - 6*(1-np.cos(d)))\\\n",
    "            +8/(5*np.pi)*(1-np.cos(d))*(np.arccos(t1) + 1/2*np.arccos(t2))\\\n",
    "            -8/(5*np.pi)*np.sin(d)*(2*(np.sqrt(2)-1)*np.arccos(t3) + 1/np.sqrt(3)*np.arccos(t4))\n",
    "    else:\n",
    "        eq = 0\n",
    "    return eq\n",
    "\n",
    "\n",
    "def predict_B(lum, model):\n",
    "    r = model.predict(lum)\n",
    "    r = r/np.linalg.norm(r, axis=1).reshape(-1,1)    \n",
    "    B = R.from_quat(np.roll(r, -1, axis=1)).inv()\n",
    "    return B\n",
    "\n",
    "\n",
    "def get_estimation_error(lum, r, model):\n",
    "    q_cubic = [[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1],\n",
    "               [1,1,1,1], [-1,1,1,1], [1,-1,1,1], [-1,-1,1,1],\n",
    "               [1,1,-1,1], [-1,1,-1,1], [1,1,1,-1], [-1,1,1,-1],\n",
    "               [1,1,0,0], [-1,1,0,0], [1,0,1,0], [-1,0,1,0],\n",
    "               [1,0,0,1], [-1,0,0,1], [0,1,1,0], [0,1,-1,0],\n",
    "               [0,0,1,1], [0,0,1,-1], [0,1,0,1], [0,-1,0,1]]\n",
    "    B_cubic = R.from_quat(np.roll(q_cubic,-1,axis=1)).inv()\n",
    "    #B_cubic = R.create_group('O')\n",
    "    \n",
    "    B_pred = predict_B(lum, model)\n",
    "    B = R.from_quat(np.roll(r, -1, axis=1)).inv()\n",
    "    mag = (B_pred.inv()*B).reduce(B_cubic).magnitude()*180/math.pi\n",
    "    return mag\n",
    "\n",
    "\n",
    "def draw_error_hist(mag, label, result_folder, savefig=True, name_fig='test'):\n",
    "    theta_list = np.arange(0,63,0.02)\n",
    "    rand_dist = np.array([random_misorientations(theta) for theta in theta_list])\n",
    "\n",
    "    plt.style.use('default')\n",
    "    plt.style.use('normal.mplstyle')\n",
    "    fig, ax = plt.subplots(figsize=(4,3))\n",
    "\n",
    "    hist = ax.hist(mag, bins=np.arange(0,63,0.5), density=True, label=label)\n",
    "    plot = ax.plot(theta_list, rand_dist, 'k-', label='Random (cubic)', )\n",
    "    \n",
    "    ax.set_xlabel('Estimation error (°)')\n",
    "    ax.set_ylabel('Density (-)')\n",
    "    ax.legend()\n",
    "    if savefig:\n",
    "        fig.savefig(f'{result_folder}/histogram_reduced_{name_fig}.png', dpi=300)\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6934f-87b6-414c-9d95-39b8497ceff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "lum60_pre = np.vstack([np.load(f'{folder}/lum_mean_{ingot}_{wafer_num}_60.npy') for ingot, wafer_num in wafers_predict])\n",
    "lum45_pre = np.vstack([np.load(f'{folder}/lum_mean_{ingot}_{wafer_num}_45.npy') for ingot, wafer_num in wafers_predict])\n",
    "lum30_pre = np.vstack([np.load(f'{folder}/lum_mean_{ingot}_{wafer_num}_30.npy') for ingot, wafer_num in wafers_predict])\n",
    "lum_pre = np.array([lum60_pre,lum45_pre,lum30_pre])\n",
    "lum_pre = lum_pre.transpose(1,2,0)\n",
    "r_pre = np.vstack([np.load(f'npy_data/q_wxyz_asscipy_{ingot}_{wafer_num}.npy') for ingot, wafer_num in wafers_predict ])\n",
    "r_pre = np.array([r0/L for r0,L in zip(r_pre, np.linalg.norm(r_pre, axis=1))])\n",
    "r_pre = r_pre*np.sign(r_pre[:,-1]).reshape(-1,1)\n",
    "lum_test = np.copy(lum_pre)\n",
    "r_test = np.copy(r_pre)\n",
    "\n",
    "mag_test = get_estimation_error(lum_test, r_test, model)\n",
    "mag_valid = get_estimation_error(lum_valid, r_valid, model)\n",
    "label_valid = 'Validation (same ingot)'\n",
    "fig, ax = draw_error_hist(mag_valid, label_valid, result_folder=result_folder, name_fig='K2')\n",
    "label_test = 'Test (another ingot)'\n",
    "fig, ax = draw_error_hist(mag_test, label_test, result_folder=result_folder, name_fig='K3')\n",
    "\n",
    "# report test performance\n",
    "mag = mag_test\n",
    "print('-- Test --')\n",
    "report_data_mean = f'Mean GDE : {np.mean(mag):.2f}°'\n",
    "report_data_median = f'Median of GDE : {np.median(mag):.2f}°'\n",
    "print(report_data_mean)\n",
    "print(report_data_median)\n",
    "\n",
    "print(np.percentile(mag, [75, 50, 25]))\n",
    "print(np.mean(mag), np.std(mag))\n",
    "\n",
    "# report validation performance\n",
    "mag = mag_valid\n",
    "print('-- Validation --')\n",
    "report_data_mean = f'Mean GDE : {np.mean(mag):.2f}°'\n",
    "report_data_median = f'Median of GDE : {np.median(mag):.2f}°'\n",
    "print(report_data_mean)\n",
    "print(report_data_median)\n",
    "\n",
    "print(np.percentile(mag, [75, 50, 25]))\n",
    "print(np.mean(mag), np.std(mag))\n",
    "\n",
    "# Box plot\n",
    "df = pd.concat([pd.melt(pd.DataFrame({'Valid': mag_valid})),\n",
    "               pd.melt(pd.DataFrame({'Test': mag_test}))])\n",
    "\n",
    "\n",
    "cm = 1/2.54\n",
    "fig, ax = plt.subplots(figsize=(8*cm, 6*cm))\n",
    "\n",
    "sns.boxplot(x='variable', y='value', data=df, showfliers=False, ax=ax, color='w')\n",
    "plt.setp(ax.artists, edgecolor='k', lw=0.5)\n",
    "plt.setp(ax.lines, color='k', lw=0.5)\n",
    "\n",
    "sns.swarmplot(x='variable', y='value', data=df, color='red', ax=ax, size=0.4)\n",
    "\n",
    "plt.xticks(fontsize=11)\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel('Estimation error (°)')\n",
    "ax.set_ylim([0,63])\n",
    "\n",
    "fig.savefig(f'{result_folder}/boxplot.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
